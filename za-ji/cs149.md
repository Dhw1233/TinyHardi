# CS149

首先强调了并行提高运算效率的原理，当我们把processor中所有的transistor都用来给单stream instruction加速可以达到100%，但是构建多个core每个core降低到75% ，这样潜在的提升效率就是1.5x，这为并行提供了可能

首先考虑一个简单的C++ demo：

```
// Some code
void sinx(int N, int terms, float* x ,float* y){
    for(int i = 0 ; i < N ;i++){
        float value = x[i];
        float numer = x[i] ^ 3;
        int  denom = 6;
        int sign = -1;
        for (int j = 0;j < terms;j++){
            ...
        }
        y[i] = value;
    }    
}
```

这段代码对x中的每个元素进行操作，但是没有考虑并行，考虑并行需要以下代码：

```
// Some code
void parallel_sinx(int N , int  terms,float* x, float* y){
    std::thread my_thread;
    my_args args;
    args.N = N / 2;
    args.terms = terms;
    args.x = x;
    args.y = y;
    my_thread = std::thread(sinx, &args);
    sinx(N - args.N , terms, x + args.N,y + args.N);
    my_thread.join();
}
```

在这段代码中，我们同时并行了两个相同的进程，使用std::thread 创建的线程处理前一半数组，而使用的主线程则对后一半数据进行操作。

这门课首先就是介绍了SIMD 跟 各种各样的processor架构，superscaler以及多处理器并行，个人认为讲解的非常清楚，然后就是普及了一下ISPC编程，在处理并行的时候需要详细分析不同instruction之间的依赖性，以及启动并行的时候什么时候采用多核并行处理任务，何时采用单核多线程，以及上下文切换的开销。（笔者在做第一个assignment的时候才知道CPU读写是在CPU cache中进行，load + unload 两次，之前画CPU的时候由于是模拟体现不出来cache读写速度快的优点，所以对指令的执行认识不够深刻）。
